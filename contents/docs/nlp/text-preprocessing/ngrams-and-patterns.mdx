---
title: N-grams and Pattern Matching
---

N-grams are contiguous sequences of n items from a text, while pattern matching involves identifying specific text patterns. These techniques are fundamental for various NLP tasks, from language modeling to text analysis.

## N-grams

### Types of N-grams
1. **Unigrams** (n=1): Individual tokens
2. **Bigrams** (n=2): Pairs of consecutive tokens
3. **Trigrams** (n=3): Sequences of three tokens

### Implementation

```python
from nltk import ngrams
from nltk.tokenize import word_tokenize

def generate_ngrams(text, n):
    tokens = word_tokenize(text)
    # Generate n-grams
    n_grams = list(ngrams(tokens, n))
    return n_grams

# Example usage
text = "The quick brown fox"
bigrams = generate_ngrams(text, 2)
# Result: [('The', 'quick'), ('quick', 'brown'), ('brown', 'fox')]
```

### Applications
1. **Language Modeling**:
   - Predicting next words
   - Text generation
   - Spelling correction

2. **Feature Extraction**:
   - Document classification
   - Text similarity
   - Plagiarism detection

## Pattern Matching

### Regular Expressions
Common patterns for text analysis:

```python
import re

def find_patterns(text):
    # Email pattern
    emails = re.findall(r'\b[\w\.-]+@[\w\.-]+\.\w+\b', text)
    
    # URL pattern
    urls = re.findall(r'https?://\S+|www\.\S+', text)
    
    # Phone numbers
    phones = re.findall(r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b', text)
    
    return emails, urls, phones
```

### Advanced Pattern Matching

1. **Named Entity Patterns**:
```python
import spacy

nlp = spacy.load('en_core_web_sm')

def find_entities(text):
    doc = nlp(text)
    entities = [(ent.text, ent.label_) for ent in doc.ents]
    return entities
```

2. **Custom Pattern Matching**:
```python
def match_custom_pattern(text, pattern):
    matches = re.finditer(pattern, text)
    return [match.group() for match in matches]
```

## Skip-grams

Skip-grams are like n-grams but allow for gaps between tokens:

```python
def generate_skipgrams(text, n, k):
    """
    Generate skipgrams where n is the n-gram size
    and k is the skip distance
    """
    tokens = word_tokenize(text)
    skipgrams = []
    for i in range(len(tokens) - n + 1):
        for j in range(k + 1):
            if i + n + j <= len(tokens):
                skipgram = tokens[i:i+n:j+1]
                skipgrams.append(tuple(skipgram))
    return skipgrams
```

## Best Practices

### 1. Performance Optimization
- Use appropriate data structures
- Consider memory constraints
- Implement efficient algorithms

### 2. Pattern Design
- Balance precision and recall
- Handle edge cases
- Consider language specifics

### 3. Validation
- Test with diverse inputs
- Verify pattern accuracy
- Monitor performance

## Common Applications

1. **Text Analysis**:
   - Feature extraction
   - Pattern recognition
   - Sequence modeling

2. **Information Extraction**:
   - Entity recognition
   - Relationship extraction
   - Key phrase extraction

3. **Text Generation**:
   - Language modeling
   - Text completion
   - Content generation

## Implementation Example

```python
class TextPatternAnalyzer:
    def __init__(self):
        self.nlp = spacy.load('en_core_web_sm')
        
    def analyze_text(self, text):
        # Generate n-grams
        unigrams = generate_ngrams(text, 1)
        bigrams = generate_ngrams(text, 2)
        
        # Find patterns
        entities = self.find_entities(text)
        patterns = self.find_patterns(text)
        
        return {
            'unigrams': unigrams,
            'bigrams': bigrams,
            'entities': entities,
            'patterns': patterns
        }
```

## Challenges

1. **Scalability**:
   - Processing large texts
   - Memory management
   - Computational efficiency

2. **Pattern Complexity**:
   - Handling ambiguous patterns
   - Language variations
   - Context dependency

3. **Maintenance**:
   - Updating patterns
   - Managing rules
   - Version control

## Summary

N-grams and pattern matching are essential techniques in NLP, providing powerful tools for text analysis and feature extraction. Understanding their proper implementation and applications is crucial for effective text processing systems. 